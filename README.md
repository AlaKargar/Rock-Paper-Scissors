<h1>ğŸª¨ğŸ“„âœ‚ï¸ Rock Paper Scissors Hand Recognition</h1>

<p>This is a simple <b>Computer Vision project</b> that detects whether your hand is showing 
<b>Rock (âœŠ)</b>, <b>Paper (ğŸ–ï¸)</b>, or <b>Scissors (âœŒï¸)</b> using <b>Python, OpenCV, and MediaPipe</b>.
It uses <b>hand landmarks detection</b> to count fingers and classify the gesture.</p>

<hr>

<h2>ğŸš€ Features</h2>
<ul>
  <li>Real-time hand tracking with <b>MediaPipe</b></li>
  <li>Finger counting to determine gesture</li>
  <li>Recognizes <b>Rock, Paper, Scissors</b></li>
  <li>Displays the result on the screen</li>
</ul>

<h2>ğŸ“¦ Requirements</h2>
<pre>
pip install opencv-python mediapipe
</pre>

<h2>ğŸ› ï¸ How It Works</h2>
<ol>
  <li>Capture frames from the webcam.</li>
  <li>Use <b>MediaPipe Hands</b> to detect 21 hand landmarks.</li>
  <li>Count open fingers:
    <ul>
      <li>0 fingers â†’ Rock (âœŠ)</li>
      <li>2 fingers (index + middle) â†’ Scissors (âœŒï¸)</li>
      <li>5 fingers â†’ Paper (ğŸ–ï¸)</li>
    </ul>
  </li>
  <li>Display the gesture name on the screen.</li>
</ol>

<h2>â–¶ï¸ Run the Project</h2>
<pre>
python rock_paper_scissors.py
</pre>
<p>Press <b>ESC</b> to exit.</p>

<h2>ğŸ“¸ Demo</h2>
<p>Example output (with landmarks drawn on the hand):</p>
<pre>
Rock âœŠ | Scissors âœŒï¸ | Paper ğŸ–ï¸
</pre>

<h2>ğŸ“‚ Project Structure</h2>
<pre>
.
â”œâ”€â”€ rock_paper_scissors.py   # main code
â”œâ”€â”€ README.md                # project documentation
</pre>

<h2>âœ¨ Future Improvements</h2>
<ul>
  <li>Add support for both hands</li>
  <li>Use a <b>CNN model</b> for more accurate classification</li>
  <li>Create a <b>multiplayer game mode</b></li>
</ul>

<h2>ğŸ¤ Contributing</h2>
<p>Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.</p>

<h2>ğŸ“œ License</h2>
<p>This project is licensed under the <b>MIT License</b>.</p>
